{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_DB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6U/9UAr1hLVLiT3KwNJ1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maiven/AI_Python/blob/main/Python/python_DB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQssj5D_oxuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a339f17-fd01-45b0-fc56-72109c04c89d"
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "class Database(object):\n",
        "    def __init__(self):\n",
        "        self.connection = sqlite3.connect(\"Database.db\")\n",
        "        self.cursor = self.connection.cursor()\n",
        "        self.table_name = \"Table_Example\"\n",
        "        self.cursor.execute(f\"CREATE TABLE IF NOT EXISTS {self.table_name} \\\n",
        "                            (column_1 INT, column_2 TEXT, column_3 REAL)\")\n",
        "        \n",
        "    def insert_data(self):\n",
        "        column_1 = int(input(\"Enter Int: \"))\n",
        "        column_2 = input(\"Enter String: \")\n",
        "        column_3 = float(input(\"Enter Float: \"))\n",
        "        self.cursor.execute(f\"INSERT INTO {self.table_name} \\\n",
        "            (column_1, column_2, column_3) VALUES(?,?,?)\",(column_1, column_2, column_3))\n",
        "        \n",
        "        self.connection.commit()\n",
        "        print(\"Data Saved\")\n",
        "    \n",
        "    def read_data(self):\n",
        "        self.cursor.execute(f\"SELECT * FROM {self.table_name}\")\n",
        "        for row in self.cursor.fetchall():\n",
        "            print(row)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    database = Database()\n",
        "    database.insert_data()\n",
        "    database.read_data()\n",
        "    database.cursor.close()\n",
        "    database.connection.close()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter Int: 10\n",
            "Enter String: abv\n",
            "Enter Float: 1.1\n",
            "Data Saved\n",
            "(10, 'abv', 1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "echicKOAuL-t"
      },
      "source": [
        "# Data Analysis — SQLite3 in python\n",
        "\n",
        "- SQLite3 is a free rational DB, with support on every programming language, which also means your work isn't one dimension on python but can be shared with other developers of different languages.\n",
        "\n",
        "- The average Data Science developer, will keep heaps of CSV files with data, read them one by one with Pandas, and cluster them into groups, this task is redundant, time-consuming and inefficient.\n",
        "\n",
        "- the database is one file to manage, you can retrieve data by values and not arrange it in files, you can keep results of ML algorithms or clustering algorithms, and compare different results, without passing on multiple files, and the integration with python and pandas is amazing!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP9A98vDubli"
      },
      "source": [
        "## Creating a Database\n",
        "\n",
        "- Sqlite3 comes in python standard library, though ill-use pandas as well in the rest of this article.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfW2J1yluLvb"
      },
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "with sqlite3.connect('example.db') as conn:\n",
        "    cursor = conn.cursor()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mog1dHZ6uiUk"
      },
      "source": [
        "- “conn” is representing the connection to the database, while the cursor variable represents the cursor (object) on the DB in that connection.\n",
        "\n",
        "- At the very basics, The cursor will let the user, insert, delete, or update data while you are connected.\n",
        "\n",
        "- And the connection itself will be used if to save changes (commit) or revert (rollback).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkcl3xqtulw1"
      },
      "source": [
        "## Creating Tables and Inserting Data\n",
        "\n",
        "- After the connection has been made, creating a table in SQLite3 is very simple\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUcF7ga2uH_H",
        "outputId": "0b49ffa8-c71c-49e8-e3e0-2dcae90e7194"
      },
      "source": [
        "fields = \"id, street, size, number_of_rooms, parking, price\"\n",
        "query = f\"create TABLE HOME_PRICES ({fields})\"\n",
        "cursor.execute(query)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7fe9ceca83b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7mdfTBRuqUR"
      },
      "source": [
        "- The prior code created a table inside our database, with the fields\n",
        "\n",
        "      id\n",
        "      street\n",
        "      size\n",
        "      number_of_rooms\n",
        "      parking\n",
        "      price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hn-QHg5u1iX"
      },
      "source": [
        "- This way, we have entered 3 rows into our DB, we can alter or view them in the future.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5cpOflkuozy",
        "outputId": "c95cf4db-7978-4272-87be-13cbed768ef2"
      },
      "source": [
        "houses = [\n",
        "    (1, 'first', 110, 4, 1, 100000),\n",
        "    (2, 'second', 90, 3, 0, 65000),\n",
        "    (3, 'second', 90, 3, 1, 72000)\n",
        "]\n",
        "cursor.executemany('insert into HOME_PRICES values (?, ?, ?, ?, ?, ?)', houses)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7fe9ceca83b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybLHh2qAu3FA"
      },
      "source": [
        "## Commit VS Rollback\n",
        "\n",
        "- When we connect to the database, we create a session.\n",
        "\n",
        "- Everything we do currently is being performed within the session.\n",
        "\n",
        "- But the changes we have made are not finalized until we decided so.\n",
        "\n",
        "- Committing a session — means keeping all the changes we have made inside the database while choosing rollback — keeps the DB intact.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAXqsN40u_e4"
      },
      "source": [
        "## Reading with Pandas\n",
        "\n",
        "- Sqlite3 has a great way of reading data, but this doesn’t mean using pandas won’t make our life a bit easier.\n",
        "\n",
        "- If you are trying to replace the famous read_csv method and CSV files in one simple database, you’ll probably want your data in pandas format anyway\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjXWkx-puzl7",
        "outputId": "fc53fc83-f176-4236-e719-41f68e80f3b4"
      },
      "source": [
        "with sqlite3.connect('example.db') as conn:\n",
        "    df = pd.read_sql(\"select * from HOME_PRICES\", conn)\n",
        "    print(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [id, street, size, number_of_rooms, parking, price]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xATdYRVvE69"
      },
      "source": [
        "## Writing Pandas DataFrames to DB\n",
        "\n",
        "- writing your CSV data into the Database is very simple, here is a small snippet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "u36vv8sovDrB",
        "outputId": "de733885-c534-4cc6-c43c-8aa790ccfb01"
      },
      "source": [
        "with sqlite3.connect('example.db') as conn:\n",
        "\n",
        "    # creating a cursor\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # reading your own data\n",
        "    df = pd.read_csv(\"your_csv.csv\")\n",
        "\n",
        "    # inserting data\n",
        "    rows = [row for name, row in df.iterrows()]\n",
        "    cursor.executemany(\n",
        "        'insert into HOME_PRICES values (?, ?, ?, ?, ?, ?)', rows\n",
        "    )\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c2ad5ff4efb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# reading your own data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"your_csv.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# inserting data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_csv.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuJzNugFvHl0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}