- ì°¸ì¡° : https://wikidocs.net/26793
- http://sanghun.xyz/2017/12/mac-apche-spark-%EC%84%A4%EC%B9%98/


Last login: Mon Mar 15 09:39:33 on console
(base) chodaehee@codestates-CDHui-MacBookPro ~ % spark
zsh: command not found: spark
(base) chodaehee@codestates-CDHui-MacBookPro ~ % ls
Applications			__pycache__
Desktop				airflow
Documents			app.rb
Downloads			handler.js
Dropbox				hello-serverless
Gemfile				logs
Gemfile.lock			notebook
Library				requirements.txt
Movies				result_eg.txt
Music				result_eg2.txt
Pictures			result_eg3.txt
Postman Agent			rubygems-3.2.13
Projects			serverless.yml
Public				spark
Untitled.ipynb			wild-rides-serverless-demo
Untitled1.ipynb			wordpress
VirtualBox VMs
(base) chodaehee@codestates-CDHui-MacBookPro ~ % cd spark
(base) chodaehee@codestates-CDHui-MacBookPro spark % ls
spark-2.1.0-bin-hadoop2.7
(base) chodaehee@codestates-CDHui-MacBookPro spark % cd spark-2.1.0-bin-hadoop2.7
(base) chodaehee@codestates-CDHui-MacBookPro spark-2.1.0-bin-hadoop2.7 % ls
LICENSE		RELEASE		examples	sbin
NOTICE		bin		jars		yarn
R		conf		licenses
README.md	data		python
(base) chodaehee@codestates-CDHui-MacBookPro spark-2.1.0-bin-hadoop2.7 % cd b
in
(base) chodaehee@codestates-CDHui-MacBookPro bin % ls
beeline			run-example		spark-sql
beeline.cmd		run-example.cmd		spark-submit
find-spark-home		spark-class		spark-submit.cmd
load-spark-env.cmd	spark-class.cmd		spark-submit2.cmd
load-spark-env.sh	spark-class2.cmd	sparkR
pyspark			spark-shell		sparkR.cmd
pyspark.cmd		spark-shell.cmd		sparkR2.cmd
pyspark2.cmd		spark-shell2.cmd
(base) chodaehee@codestates-CDHui-MacBookPro bin % bin
zsh: command not found: bin
(base) chodaehee@codestates-CDHui-MacBookPro bin % cd ..
(base) chodaehee@codestates-CDHui-MacBookPro spark-2.1.0-bin-hadoop2.7 % bin
zsh: command not found: bin
(base) chodaehee@codestates-CDHui-MacBookPro spark-2.1.0-bin-hadoop2.7 % spar
k bin
zsh: command not found: spark
(base) chodaehee@codestates-CDHui-MacBookPro spark-2.1.0-bin-hadoop2.7 % cd b
in
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark
zsh: command not found: spark
(base) chodaehee@codestates-CDHui-MacBookPro bin % ls
beeline			run-example		spark-sql
beeline.cmd		run-example.cmd		spark-submit
find-spark-home		spark-class		spark-submit.cmd
load-spark-env.cmd	spark-class.cmd		spark-submit2.cmd
load-spark-env.sh	spark-class2.cmd	sparkR
pyspark			spark-shell		sparkR.cmd
pyspark.cmd		spark-shell.cmd		sparkR2.cmd
pyspark2.cmd		spark-shell2.cmd
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-shell
/opt/anaconda3/bin/spark-shell: line 60: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-submit: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-sql
/opt/anaconda3/bin/spark-sql: line 25: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-submit: No such file or directory
/opt/anaconda3/bin/spark-sql: line 25: exec: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-submit: cannot execute: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-submit
/opt/anaconda3/bin/spark-submit: line 27: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: No such file or directory
/opt/anaconda3/bin/spark-submit: line 27: exec: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: cannot execute: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % ls
beeline			run-example		spark-sql
beeline.cmd		run-example.cmd		spark-submit
find-spark-home		spark-class		spark-submit.cmd
load-spark-env.cmd	spark-class.cmd		spark-submit2.cmd
load-spark-env.sh	spark-class2.cmd	sparkR
pyspark			spark-shell		sparkR.cmd
pyspark.cmd		spark-shell.cmd		sparkR2.cmd
pyspark2.cmd		spark-shell2.cmd
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-submit.cmd
/opt/anaconda3/bin/spark-submit.cmd: line 1: @echo: command not found
: command not foundspark-submit.cmd: line 2:
: command not foundspark-submit.cmd: line 3: rem
/opt/anaconda3/bin/spark-submit.cmd: line 4: syntax error near unexpected token `('
/opt/anaconda3/bin/spark-submit.cmd: line 4: `rem Licensed to the Apache Soft'are Foundation (ASF) under one or more
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-submit
/opt/anaconda3/bin/spark-submit: line 27: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: No such file or directory
/opt/anaconda3/bin/spark-submit: line 27: exec: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: cannot execute: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-submit --master yarn

/opt/anaconda3/bin/spark-submit: line 27: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: No such file or directory
/opt/anaconda3/bin/spark-submit: line 27: exec: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: cannot execute: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-submit --master yarn \
  --queue spark_queue \
  --class sdk.spark.SparkWordCount \
  --conf spark.shuffle.service.enabled=true \
  ./Spark-Example.jar

/opt/anaconda3/bin/spark-submit: line 27: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: No such file or directory
/opt/anaconda3/bin/spark-submit: line 27: exec: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-class: cannot execute: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-shell --master yarn --queue queue_name
/opt/anaconda3/bin/spark-shell: line 60: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-submit: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-shell --master yarn --queue
/opt/anaconda3/bin/spark-shell: line 60: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-submit: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-shell --master yarn
/opt/anaconda3/bin/spark-shell: line 60: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-submit: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-shell
/opt/anaconda3/bin/spark-shell: line 60: /usr/local/Cellar/apache-spark/3.0.2/libexec/bin/spark-submit: No such file or directory
(base) chodaehee@codestates-CDHui-MacBookPro bin % spark-shell.cmd
/opt/anaconda3/bin/spark-shell.cmd: line 1: @echo: command not found
: command not foundspark-shell.cmd: line 2:
: command not foundspark-shell.cmd: line 3: rem
/opt/anaconda3/bin/spark-shell.cmd: line 4: syntax error near unexpected token `('
/opt/anaconda3/bin/spark-shell.cmd: line 4: `rem Licensed to the Apache Softw're Foundation (ASF) under one or more
(base) chodaehee@codestates-CDHui-MacBookPro bin % scala
Welcome to Scala 2.13.5 (OpenJDK 64-Bit Server VM, Java 15.0.2).
Type in expressions for evaluation. Or try :help.

scala> exit
       ^
       error: not found: value exit

scala> exit()
       ^
       error: not found: value exit

scala> cd ..
           ^
       error: identifier expected but '.' found.

scala>
:quit
(base) chodaehee@codestates-CDHui-MacBookPro bin % cd ~
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew tap caskroom/versions
Updating Homebrew...
==> Auto-updated Homebrew!
Updated 3 taps (homebrew/core, homebrew/cask and caskroom/cask).
==> New Formulae
as-tree                   pyqt-builder              qt-percona-server
glibc                     pyqt-networkauth          qt-postgresql
haskell-language-server   pyqt@5                    qt-unixodbc
iconsur                   qt-libiodbc               xray
libunwind                 qt-mariadb
pyqt-3d                   qt-mysql
==> Updated Formulae
Updated 206 formulae.
==> New Casks
code-composer-studio      simplelink-msp432-sdk     uniflash
code-composer-studio      simplelink-msp432e4-sdk   uniflash
simplelink-msp432-sdk     simplelink-msp432e4-sdk
==> Updated Casks
Updated 188 casks.

Error: caskroom/versions was moved. Tap homebrew/cask-versions instead.
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew tap caskroom/versions
Error: caskroom/versions was moved. Tap homebrew/cask-versions instead.
(base) chodaehee@codestates-CDHui-MacBookPro ~ % homebrew/cask-versions
zsh: no such file or directory: homebrew/cask-versions
(base) chodaehee@codestates-CDHui-MacBookPro ~ % tap homebrew/cask-versions
zsh: command not found: tap
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew cask search java

Error: Unknown command: cask
(base) chodaehee@codestates-CDHui-MacBookPro ~ % /usr/libexec/java_home
/Library/Java/JavaVirtualMachines/openjdk.jdk/Contents/Home
(base) chodaehee@codestates-CDHui-MacBookPro ~ % export
COLORFGBG='7;0'
COLORTERM=truecolor
CONDA_DEFAULT_ENV=base
CONDA_EXE=/opt/anaconda3/bin/conda
CONDA_PREFIX=/opt/anaconda3
CONDA_PROMPT_MODIFIER='(base) '
CONDA_PYTHON_EXE=/opt/anaconda3/bin/python
CONDA_SHLVL=1
HOME=/Users/chodaehee
ITERM_PROFILE=Default
ITERM_SESSION_ID=w0t0p0:60BEB22D-694D-452E-9BBA-DEF0F5C26D0F
LANG=ko_KR.UTF-8
LC_TERMINAL=iTerm2
LC_TERMINAL_VERSION=3.4.4
LOGNAME=chodaehee
OLDPWD=/Users/chodaehee/spark/spark-2.1.0-bin-hadoop2.7/bin
PATH='/usr/local/opt/openjdk@8/bin:/usr/local/opt/ruby/bin:/usr/local/opt/scala@2.13.4/bin:/usr/local/opt/openjdk/bin:/Users/chodaehee/.rbenv/shims:/Users/chodaehee/.rbenv/bin:/opt/anaconda3/bin:/opt/anaconda3/condabin:/Library/Frameworks/Python.framework/Versions/3.9/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/share/dotnet:~/.dotnet/tools:/Library/Apple/usr/bin:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/usr/local/Cellar/apache-spark/3.0.2/libexec'
PWD=/Users/chodaehee
PYSPARK_DRIVER_PYTHON=jupyter
PYSPARK_DRIVER_PYTHON_OPTS=notebook
PYSPARK_PYTHON=python3
RBENV_SHELL=zsh
SHELL=/bin/zsh
SHLVL=1
SPARK_HOME=/usr/local/Cellar/apache-spark/3.0.2/libexec
SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.b4f7fzd1qn/Listeners
TERM=xterm-256color
TERM_PROGRAM=iTerm.app
TERM_PROGRAM_VERSION=3.4.4
TERM_SESSION_ID=w0t0p0:60BEB22D-694D-452E-9BBA-DEF0F5C26D0F
TMPDIR=/var/folders/mm/tct16mls78x4zqthwnxxlk140000gn/T/
USER=chodaehee
XPC_FLAGS=0x0
XPC_SERVICE_NAME=0
_CE_CONDA=''
_CE_M=''
__CF_USER_TEXT_ENCODING=0x0:3:51
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew cask install java9
Error: Unknown command: cask
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew cask install java
Error: Unknown command: cask
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew install java
Warning: openjdk 15.0.2 is already installed and up-to-date.
To reinstall 15.0.2, run:
  brew reinstall openjdk
(base) chodaehee@codestates-CDHui-MacBookPro ~ % apache-spark
zsh: command not found: apache-spark
(base) chodaehee@codestates-CDHui-MacBookPro ~ % ls
Applications			__pycache__
Desktop				airflow
Documents			app.rb
Downloads			handler.js
Dropbox				hello-serverless
Gemfile				logs
Gemfile.lock			notebook
Library				requirements.txt
Movies				result_eg.txt
Music				result_eg2.txt
Pictures			result_eg3.txt
Postman Agent			rubygems-3.2.13
Projects			serverless.yml
Public				spark
Untitled.ipynb			wild-rides-serverless-demo
Untitled1.ipynb			wordpress
VirtualBox VMs
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew install apache-spark

Warning: apache-spark 3.1.1 is already installed and up-to-date.
To reinstall 3.1.1, run:
  brew reinstall apache-spark
(base) chodaehee@codestates-CDHui-MacBookPro ~ % export SPARK_HOME=/usr/local/Cellar/apache-spark/3.1.1/libexec

(base) chodaehee@codestates-CDHui-MacBookPro ~ % export PATH=$PATH:$SPARK_HOME

(base) chodaehee@codestates-CDHui-MacBookPro ~ % export SPARK_LOCAL_IP=127.0.0.1
(base) chodaehee@codestates-CDHui-MacBookPro ~ % export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/build:$PYTHONPATH

(base) chodaehee@codestates-CDHui-MacBookPro ~ % python
Python 3.8.3 (default, Jul  2 2020, 11:26:31)
[Clang 10.0.0 ] :: Anaconda, Inc. on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>>
KeyboardInterrupt
>>>
zsh: suspended  python
(base) chodaehee@codestates-CDHui-MacBookPro ~ % export PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH

(base) chodaehee@codestates-CDHui-MacBookPro ~ % spark-shell
21/03/15 20:52:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://localhost:4040
Spark context available as 'sc' (master = local[*], app id = local-1615809151815).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.1.1
      /_/

Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_282)
Type in expressions to have them evaluated.
Type :help for more information.

scala> %
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew install yarn
==> Downloading https://yarnpkg.com/downloads/1.22.10/yarn-v1.22.10.tar.gz
==> Downloading from https://github-releases.githubusercontent.com/49970642/3
#=#=#                                                                        ####                                                                       6.###################                                                       27.################################                                          45.#####################################                                     52.##########################################################                80.######################################################################## 100.0%
Error: Cannot install yarn because conflicting formulae are installed.
  hadoop: because both install `yarn` binaries

Please `brew unlink hadoop` before continuing.

Unlinking removes a formula's symlinks from /usr/local. You can
link the formula again after the install finishes. You can --force this
install, but the build may fail or cause obscure side effects in the
resulting software.
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew unlink hadoop
Unlinking /usr/local/Cellar/hadoop/3.3.0... 28 symlinks removed.
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew install yarn
==> Downloading https://yarnpkg.com/downloads/1.22.10/yarn-v1.22.10.tar.gz
Already downloaded: /Users/chodaehee/Library/Caches/Homebrew/downloads/1ed0a9b4d5234a1301d4f37d98ad9866a1695d91581d6020ea551b5af4d1b888--yarn-v1.22.10.tar.gz
ðŸº  /usr/local/Cellar/yarn/1.22.10: 15 files, 5MB, built in 4 seconds
(base) chodaehee@codestates-CDHui-MacBookPro ~ % spark-shell
21/03/15 20:57:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://localhost:4040
Spark context available as 'sc' (master = local[*], app id = local-1615809466819).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.1.1
      /_/

Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_282)
Type in expressions to have them evaluated.
Type :help for more information.

scala> val count = sc.parallelize(1 to 100).filter { _ =>
     |   val x = math.random
     |   val y = math.random
     |   x*x + y*y < 1
     | }.count()
[Stage 0:>                                                         (0 + 0) / [Stage 0:>                                                        (0 + 12) /                                                                              count: Long = 82

scala>

scala> println(s"Pi is roughly ${4.0 * count / 100}")
Pi is roughly 3.28

scala>

scala> %
(base) chodaehee@codestates-CDHui-MacBookPro ~ % pyspark
[I 20:58:07.134 NotebookApp] JupyterLab extension loaded from /opt/anaconda3/lib/python3.8/site-packages/jupyterlab
[I 20:58:07.134 NotebookApp] JupyterLab application directory is /opt/anaconda3/share/jupyter/lab
[I 20:58:07.138 NotebookApp] Serving notebooks from local directory: /Users/chodaehee
[I 20:58:07.138 NotebookApp] Jupyter Notebook 6.1.4 is running at:
[I 20:58:07.138 NotebookApp] http://localhost:8888/?token=29fdfc29650352317544b4a672886db4b7bcdc4333209809
[I 20:58:07.138 NotebookApp]  or http://127.0.0.1:8888/?token=29fdfc29650352317544b4a672886db4b7bcdc4333209809
[I 20:58:07.138 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 20:58:07.150 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///Users/chodaehee/Library/Jupyter/runtime/nbserver-55768-open.html
    Or copy and paste one of these URLs:
        http://localhost:8888/?token=29fdfc29650352317544b4a672886db4b7bcdc4333209809
     or http://127.0.0.1:8888/?token=29fdfc29650352317544b4a672886db4b7bcdc4333209809
[I 20:58:12.192 NotebookApp] Creating new notebook in
[W 20:58:12.667 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.679 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.726 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.732 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.757 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.768 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.795 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.806 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.855 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:12.862 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.024 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.029 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.102 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.108 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.143 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.148 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.164 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.172 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.190 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.198 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.233 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.238 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.363 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 20:58:13.368 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[I 20:58:13.920 NotebookApp] Kernel started: c4517c44-b241-44bb-aa9d-91e1fd4e34f1, name: python3
21/03/15 20:58:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                        (0 + 12) /                                                                              [I 21:00:13.832 NotebookApp] Saving file at /Untitled2.ipynb
^C[I 21:00:42.732 NotebookApp] interrupted
Serving notebooks from local directory: /Users/chodaehee
1 active kernel
Jupyter Notebook 6.1.4 is running at:
http://localhost:8888/?token=29fdfc29650352317544b4a672886db4b7bcdc4333209809
 or http://127.0.0.1:8888/?token=29fdfc29650352317544b4a672886db4b7bcdc4333209809
Shutdown this notebook server (y/[n])? y
[C 21:00:44.585 NotebookApp] Shutdown confirmed
[I 21:00:44.586 NotebookApp] Shutting down 1 kernel
[I 21:00:45.727 NotebookApp] Kernel shutdown: c4517c44-b241-44bb-aa9d-91e1fd4e34f1
[I 21:00:45.727 NotebookApp] Shutting down 0 terminals
(base) chodaehee@codestates-CDHui-MacBookPro ~ % .bashrc
zsh: command not found: .bashrc
(base) chodaehee@codestates-CDHui-MacBookPro ~ % vi .bashrc
(base) chodaehee@codestates-CDHui-MacBookPro ~ % pip install pyspark findspark

Requirement already satisfied: pyspark in /usr/local/Cellar/apache-spark/3.1.1/libexec/python (3.1.1)
Requirement already satisfied: findspark in /opt/anaconda3/lib/python3.8/site-packages (1.4.2)
Requirement already satisfied: py4j==0.10.9 in /opt/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9)
(base) chodaehee@codestates-CDHui-MacBookPro ~ % pip install pyspark findspark
Requirement already satisfied: pyspark in /usr/local/Cellar/apache-spark/3.1.1/libexec/python (3.1.1)
Requirement already satisfied: findspark in /opt/anaconda3/lib/python3.8/site-packages (1.4.2)
Requirement already satisfied: py4j==0.10.9 in /opt/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9)
(base) chodaehee@codestates-CDHui-MacBookPro ~ % pyspark
[I 21:04:37.732 NotebookApp] JupyterLab extension loaded from /opt/anaconda3/lib/python3.8/site-packages/jupyterlab
[I 21:04:37.733 NotebookApp] JupyterLab application directory is /opt/anaconda3/share/jupyter/lab
[I 21:04:37.736 NotebookApp] Serving notebooks from local directory: /Users/chodaehee
[I 21:04:37.736 NotebookApp] Jupyter Notebook 6.1.4 is running at:
[I 21:04:37.736 NotebookApp] http://localhost:8888/?token=7000b9e1ea39a6079624e837d98f77b7d6adedc0a7902933
[I 21:04:37.736 NotebookApp]  or http://127.0.0.1:8888/?token=7000b9e1ea39a6079624e837d98f77b7d6adedc0a7902933
[I 21:04:37.736 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 21:04:37.744 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///Users/chodaehee/Library/Jupyter/runtime/nbserver-56428-open.html
    Or copy and paste one of these URLs:
        http://localhost:8888/?token=7000b9e1ea39a6079624e837d98f77b7d6adedc0a7902933
     or http://127.0.0.1:8888/?token=7000b9e1ea39a6079624e837d98f77b7d6adedc0a7902933
^C[I 21:05:23.033 NotebookApp] interrupted
Serving notebooks from local directory: /Users/chodaehee
0 active kernels
Jupyter Notebook 6.1.4 is running at:
http://localhost:8888/?token=7000b9e1ea39a6079624e837d98f77b7d6adedc0a7902933
 or http://127.0.0.1:8888/?token=7000b9e1ea39a6079624e837d98f77b7d6adedc0a7902933
Shutdown this notebook server (y/[n])?  y
[C 21:05:25.790 NotebookApp] Shutdown confirmed
[I 21:05:25.791 NotebookApp] Shutting down 0 kernels
[I 21:05:25.791 NotebookApp] Shutting down 0 terminals
(base) chodaehee@codestates-CDHui-MacBookPro ~ % import findspark
findspark.init()

function> import findspark

zsh: command not found: import
(base) chodaehee@codestates-CDHui-MacBookPro ~ % findspark.init()

function> import pyspark

(base) chodaehee@codestates-CDHui-MacBookPro ~ % sc = pyspark.SparkContext(appName="myAppName")

zsh: number expected
(base) chodaehee@codestates-CDHui-MacBookPro ~ % import os
exec(open(os.path.join(os.environ["SPARK_HOME"], 'python/pyspark/shell.py')).read())

zsh: parse error near `)'
(base) chodaehee@codestates-CDHui-MacBookPro ~ % import findspark
findspark.init()

import pyspark
sc = pyspark.SparkContext(appName="myAppName")

zsh: command not found: import
zsh: number expected
(base) chodaehee@codestates-CDHui-MacBookPro ~ % brew install apache-spark

Warning: apache-spark 3.1.1 is already installed and up-to-date.
To reinstall 3.1.1, run:
  brew reinstall apache-spark
(base) chodaehee@codestates-CDHui-MacBookPro ~ %   brew reinstall apache-spark
==> Downloading https://www.apache.org/dyn/closer.lua?path=spark/spark-3.1.1/
Already downloaded: /Users/chodaehee/Library/Caches/Homebrew/downloads/f243419f695c0dfbb5b5d1be43331881f464a6d06638945b8bc137f1efd33569--spark-3.1.1-bin-hadoop3.2.tgz
==> Reinstalling apache-spark
ðŸº  /usr/local/Cellar/apache-spark/3.1.1: 1,361 files, 242.6MB, built in 7 seconds
(base) chodaehee@codestates-CDHui-MacBookPro ~ % pyspark
[I 21:06:59.849 NotebookApp] JupyterLab extension loaded from /opt/anaconda3/lib/python3.8/site-packages/jupyterlab
[I 21:06:59.849 NotebookApp] JupyterLab application directory is /opt/anaconda3/share/jupyter/lab
[I 21:06:59.851 NotebookApp] Serving notebooks from local directory: /Users/chodaehee
[I 21:06:59.851 NotebookApp] Jupyter Notebook 6.1.4 is running at:
[I 21:06:59.851 NotebookApp] http://localhost:8888/?token=39826ff5917b8042eafcde561972e6cf94d9ae95a66af7ab
[I 21:06:59.851 NotebookApp]  or http://127.0.0.1:8888/?token=39826ff5917b8042eafcde561972e6cf94d9ae95a66af7ab
[I 21:06:59.851 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 21:06:59.857 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///Users/chodaehee/Library/Jupyter/runtime/nbserver-57628-open.html
    Or copy and paste one of these URLs:
        http://localhost:8888/?token=39826ff5917b8042eafcde561972e6cf94d9ae95a66af7ab
     or http://127.0.0.1:8888/?token=39826ff5917b8042eafcde561972e6cf94d9ae95a66af7ab
pip install pyspark findspark
^Z
zsh: suspended  pyspark
(base) chodaehee@codestates-CDHui-MacBookPro ~ % pyspark
[I 21:07:23.601 NotebookApp] The port 8888 is already in use, trying another port.
[I 21:07:23.885 NotebookApp] JupyterLab extension loaded from /opt/anaconda3/lib/python3.8/site-packages/jupyterlab
[I 21:07:23.885 NotebookApp] JupyterLab application directory is /opt/anaconda3/share/jupyter/lab
[I 21:07:23.888 NotebookApp] Serving notebooks from local directory: /Users/chodaehee
[I 21:07:23.888 NotebookApp] Jupyter Notebook 6.1.4 is running at:
[I 21:07:23.888 NotebookApp] http://localhost:8889/?token=745ed1e51d4b8e5efac27b34521b44593426cec68df7a68d
[I 21:07:23.888 NotebookApp]  or http://127.0.0.1:8889/?token=745ed1e51d4b8e5efac27b34521b44593426cec68df7a68d
[I 21:07:23.888 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 21:07:23.896 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///Users/chodaehee/Library/Jupyter/runtime/nbserver-57679-open.html
    Or copy and paste one of these URLs:
        http://localhost:8889/?token=745ed1e51d4b8e5efac27b34521b44593426cec68df7a68d
     or http://127.0.0.1:8889/?token=745ed1e51d4b8e5efac27b34521b44593426cec68df7a68d
[W 21:07:28.089 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.101 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.148 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.154 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.179 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.190 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.216 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.226 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.273 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.279 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.425 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.431 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.506 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.512 NotebookApp] Config option `template_path` not recognized by `ExporterCollapsibleHeadings`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.549 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.554 NotebookApp] Config option `template_path` not recognized by `TocExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.574 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.584 NotebookApp] Config option `template_path` not recognized by `LenvsHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.608 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.617 NotebookApp] Config option `template_path` not recognized by `LenvsTocHTMLExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.655 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.659 NotebookApp] Config option `template_path` not recognized by `LenvsLatexExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.793 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[W 21:07:28.799 NotebookApp] Config option `template_path` not recognized by `LenvsSlidesExporter`.  Did you mean one of: `extra_template_paths, template_name, template_paths`?
[I 21:07:29.420 NotebookApp] Kernel started: f940971f-bc71-4227-ad00-1bddb322f690, name: python3
21/03/15 21:07:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 21:09:29.788 NotebookApp] Saving file at /Untitled2.ipynb
[I 21:11:29.404 NotebookApp] Saving file at /Untitled2.ipynb
[I 21:13:29.408 NotebookApp] Saving file at /210315.ipynb
[Stage 0:>                                                          (0 + 1) /[Stage 0:===========================================================(1 + 0) /                                                                             [I 21:13:46.575 NotebookApp] Saving file at /210315.ipynb
[I 21:15:29.570 NotebookApp] Saving file at /210315.ipynb
[I 21:17:29.650 NotebookApp] Saving file at /210315.ipynb
[I 21:18:43.658 NotebookApp] Saving file at /210315.ipynb
[I 21:19:29.387 NotebookApp] Saving file at /210315.ipynb
[I 21:25:25.995 NotebookApp] Saving file at /210315.ipynb
[I 21:25:27.391 NotebookApp] Starting buffering for f940971f-bc71-4227-ad00-1bddb322f690:c6bcda54097d4a35804904e91aa65ccd




http://127.0.0.1:4040/jobs/

![image](https://user-images.githubusercontent.com/10266436/111150340-52dff480-85d1-11eb-89f4-dcea82e14049.png)
